# -*- coding: utf-8 -*-
"""Python Data mining.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fBdeRhf6INnH9FcrEGddY_-zvGGjRr7l

# 爬蟲實例

## lxml：yahoo!股市 即時成交明細
"""

import requests
url = "https://tw.stock.yahoo.com/q/ts?s=2330"
response = requests.get(url)
html = response.text
# print(html)

from lxml import etree
xpath_1 = "//html/body/center/table[1]/tbody/tr/td[1]/table[2]//text()"
xpath_2 = "//table[@border=0 and @width=700][1]//td//text()"
page = etree.HTML(html)
result = page.xpath(xpath_2)
result_list = []
for index,row in enumerate(result):
    if index>=10 and index%7==3:
        # print(index,row)
        row_list = result[index:index+7]
        # print(index,row_list)
        if ":" in row_list[0]:
            result_list.append(row_list)
for i in (result_list):
    print(i)

"""## json：[yahoo!股市 每日技術分析](https://tw.stock.yahoo.com/q/bc?s=2330)"""

import requests
url = "https://tw.quote.finance.yahoo.net/quote/q?type=ta&perd=d&mkt=10&sym=2330&v=1"
response = requests.get(url)
html = response.text
print(html)

"""[JSON Parser Online](http://json.parser.online.fr/)"""

import json
data = html.split("null(")[-1].split(");")[0]
json_data = json.loads(data)
for ele in json_data["ta"]:
    print(ele["t"],ele["o"],ele["h"],ele["l"],ele["c"],ele["v"])

"""## 函式：[台灣銀行的股市資訊網](https://fund.bot.com.tw/z/index.htm)"""

import requests
def get_html(stock_id):
    url = "https://fund.bot.com.tw/Z/ZC/ZCW/CZKC1.djbcd?a={}&b=D&c=10".format(stock_id)
    resp_html = requests.get(url)
    html = resp_html.text
    return html

def parse_html(html):
    group = html.split(" ")
    g_date,g_open,g_high,g_low,g_close,g_volume = group[0:5+1]
    g_date = g_date.split(",")
    g_open = g_open.split(",")
    g_high = g_high.split(",")
    g_low = g_low.split(",")
    g_close = g_close.split(",")
    g_volume = g_volume.split(",")
    datas = []
    for i in range(0,len(g_date)):
        datas.append([g_date[i],g_open[i],g_high[i],g_low[i],g_close[i],g_volume[i]])
    return datas

for stock_id in [2330,2317]:
    html = get_html(stock_id)
    datas = parse_html(html)
    for i in range(0,len(datas)):
        print(stock_id,datas[i])

"""# [API 使用 - LINE Notify](https://marsw.github.io/Python-Tutorial/07_v2_applications.slides.html#/2)"""

import requests
token = "你的權杖"
msg = "用 Python 發 LINE Notify 通知"

url = "https://notify-api.line.me/api/notify"
headers = {
    "Authorization": "Bearer " + token, 
    "Content-Type" : "application/x-www-form-urlencoded"
}
payload = {'message': msg}
r = requests.post(url, headers = headers, params = payload)

"""# Flask & SQL

## 環境設定
"""

!pip install flask-ngrok

"""## DB 設定"""

import sqlite3
conn = sqlite3.connect('stocks.db') # 如果資料庫不存在，會自動幫你建立
sql_create_table = """
CREATE TABLE `stock_date` (
	`stock_id`	INTEGER,
	`date`	TEXT,
	`open`	REAL,
	`high`	REAL,
	`low`	REAL,
	`close`	REAL,
	`volume`	INTEGER
)
"""
cursor = conn.execute(sql_create_table)
conn.close()

datas_2330 = [
    ['2020/03/02', '308', '317', '308', '311', '86373'],
    ['2020/03/03', '318.5', '320', '316', '317.5', '55169'],
    ['2020/03/04', '322', '322', '317', '320.5', '44745'],
    ['2020/03/05', '325', '326', '323', '323', '38224'],
    ['2020/03/06', '320', '320.5', '315', '315', '52808']
]
datas_2317 = [
    ['2020/03/02', '78.2', '80.3', '78.1', '79.2', '54992'],
    ['2020/03/03', '81.1', '82', '80.6', '81', '34822'],
    ['2020/03/04', '81.5', '81.9', '81.1', '81.7', '29908'],
    ['2020/03/05', '83.3', '83.6', '82.6', '82.7', '36950'],
    ['2020/03/06', '81.6', '81.7', '80.7', '80.8', '38713']
]
def ins_stock_data(stock_id,datas):
    conn = sqlite3.connect('stocks.db')
    for row in datas:
        d, o, h, l, c, v = row
        sql_ins = """
            INSERT INTO `stock_date` (`stock_id`, `date`, `open`, `high`, `low`, `close`, `volume`)  
            VALUES ( {} ,'{}', {}, {}, {}, {}, {} )
        """.format(stock_id,d.replace("/","-"),float(o),float(h),float(l),float(c),int(v))
        cursor = conn.execute(sql_ins)
        cursor = conn.commit()
    conn.close()

ins_stock_data(2330,datas_2330)
ins_stock_data(2317,datas_2317)

"""## Template
- 在 `templates` 資料夾有檔案 `stock_date.html`
"""

filecontent = """<h1>股票代碼: {{ stock_id }}</h1>
<h1>查詢日期: {{ date_start }}</h1>
<a href='/'>回首頁</a>
<table>
    <thead>
        <tr>
            <th>日期</th>
            <th>開盤價</th>
            <th>最高價</th>
            <th>最低價</th>
            <th>收盤價</th>
            <th>成交量</th>
        </tr>
    </thead>
    <tbody>
        {% for row in datas %}
        <tr>
            <td>{{ row[0] }}</td>
            <td>{{ row[1] }}</td>
            <td>{{ row[2] }}</td>
            <td>{{ row[3] }}</td>
            <td>{{ row[4] }}</td>
            <td>{{ row[5] }}</td>
        </tr>
        {% endfor %}
    </tbody>
</table>
"""

import os
dir_name = "templates"
if dir_name not in os.listdir():
    os.makedirs(dir_name)
fo = open("templates/stock_date.html","w") 
fo.write(filecontent)
fo.close()

"""## 網站呈現"""

from flask_ngrok import run_with_ngrok
from flask import Flask, render_template
from flask import request
import sqlite3
app = Flask(__name__)
run_with_ngrok(app)

def get_stock_datas(stock_id,date_start):
    conn = sqlite3.connect('stocks.db')
    sql = """
        SELECT `date`, `open`, `high`, `low`, `close`, `volume`
        FROM `stock_date`
        WHERE `stock_id` = {} and `date`>='{}'
        ORDER BY `date`
    """.format(stock_id,date_start)
    cursor = conn.execute(sql)
    datas = cursor.fetchall()
    return datas

@app.route("/")
def home():
    resp = """Welcome to Stock Board 
    <br> 
    <a href='/stock/2330/2020-03-05'>進入2330股票頁(路徑)</a> 
    <br> 
    <a href='/stock?stock_id=2330&date_start=2020-03-05'>進入2330股票頁(參數)</a>
    """
    return resp

@app.route("/stock/<stock_id>/<date_start>")
def get_stock_path(stock_id, date_start):
    return render_template("stock_date.html", stock_id=stock_id, date_start=date_start, datas = get_stock_datas(stock_id,date_start))

@app.route("/stock")
def get_stock_param():
    stock_id = request.args.get('stock_id')
    date_start = request.args.get('date_start')
    return render_template("stock_date.html", stock_id=stock_id, date_start=date_start, datas = get_stock_datas(stock_id,date_start))

app.run()

"""# pandas

## 數據操作與統計
"""

import pandas as pd

datas = [
    ['2330','2020/03/02', '308', '317', '308', '311', '86373'],
    ['2330','2020/03/03', '318.5', '320', '316', '317.5', '55169'],
    ['2330','2020/03/04', '322', '322', '317', '320.5', '44745'],
    ['2330','2020/03/05', '325', '326', '323', '323', '38224'],
    ['2330','2020/03/06', '320', '320.5', '315', '315', '52808'],
]
dfl = pd.DataFrame(datas)

dfl

dfl.columns = ["stock_id","date","open","high","low","close","volume"]
dfl["open"]=dfl["open"].astype(float)
dfl["high"]=dfl["high"].astype(float)
dfl["low"]=dfl["low"].astype(float)
dfl["close"]=dfl["close"].astype(float)
dfl["volume"] = dfl["volume"].astype(int)
dfl.describe()

print(dfl["open"].median())
print(dfl["open"].max())
print(dfl["open"].min())
print(dfl["open"].describe()["25%"])

dfln = dfl.copy()
dfln["CDP"]=(dfln["high"]+dfln["low"]+dfln["close"]*2)/4
dfln

"""## 區間切分 & 計算各區間個數"""

df2 = dfl.copy()
# 切分點 (配合 include_lowest, right 參數決定是否包含左右端點，左邊預設 False，右邊預設 True)
listBins = [0, 36950, 45000, 55000,60000,100000000]

# 切分區後的對應標籤
listLabels = ['0~36950','36951~45000','45001~55000','55001~60000','60001~']

df2['volume_group'] = pd.cut(df2['volume'], bins=listBins, labels=listLabels, include_lowest=True)
df2

df2["volume_group"].value_counts()

"""## [均線](https://www.cmoney.tw/learn/course/technicals/topic/485)
- (Moving Average，MA)
- 最近n日(包含當天)的平均收盤價：`MA = (c1+c2+...+cn)/n`

"""

# df_ma = pd.read_csv("2330_2020.csv")
df_ma = pd.read_csv("https://drive.google.com/uc?export=download&id=1ZNIuVf_Dz5mcHKqk6ed6ELamtQSYS-5r")
df_ma

df_ma.describe()

print((339.0+339.5+332.0+329.5+329.5)/5)

df_ma['MA_5'] = df_ma['close'].rolling(5).mean()
df_ma['MA_20'] = df_ma['close'].rolling(20).mean()
df_ma

"""# 視覺化

## matplotlib：基本畫圖
"""

import matplotlib.pyplot as plt

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

fig = plt.figure(figsize=(24, 8))
plt.scatter(df_ma["date"],df_ma["close"], color='black')
plt.plot(df_ma["date"],df_ma["MA_5"], color='blue')
plt.plot(df_ma["date"],df_ma["MA_20"], color="orange", marker='s')
plt.xticks(rotation=60)
plt.grid()
plt.show()

"""## Get Data / Data Collection by crawler

"""

import requests 
def stock_crawler(stock_id):
    url = "https://fund.bot.com.tw/Z/ZC/ZCW/CZKC1.djbcd?a={}&b=D&c=60".format(stock_id)
    resp = requests.get(url)
    html = resp.text
    group = html.split(" ")
    g_date,g_open,g_high,g_low,g_close,g_volume = group[0:5+1]
    g_date = g_date.split(",")
    g_open = g_open.split(",")
    g_high = g_high.split(",")
    g_low = g_low.split(",")
    g_close = g_close.split(",")
    g_volume = g_volume.split(",")
    datas = []
    for i in range(0,len(g_date)):
        datas.append([stock_id,g_date[i].replace("/","-"),float(g_open[i]),float(g_high[i]),float(g_low[i]),float(g_close[i]),int(g_volume[i])])
    return datas

data_2330 = stock_crawler("2330")
data_2317 = stock_crawler("2317")
data_2603 = stock_crawler("2603")

"""## ETL"""

import pandas as pd
df_2330 = pd.DataFrame(data_2330)
df_2330.columns = ["stock_id","date","open","high","low","close","volume"]
df_2317 = pd.DataFrame(data_2317)
df_2317.columns = ["stock_id","date","open","high","low","close","volume"]
df_2603 = pd.DataFrame(data_2603)
df_2603.columns = ["stock_id","date","open","high","low","close","volume"]
df = pd.concat([df_2330,df_2317,df_2603])
df.columns = ["stock_id","date","open","high","low","close","volume"]
df

"""## Feature Engineering：

#### 獨立性：
- 開盤價跟收盤價差異不會太大 => 用昨日價格預測
- 均線包含當天 => 去除今天
"""

### Explore ==========
df_2330['MA_5'] = df_2330['close'].rolling(5).mean()
plt.scatter(df_2330["MA_5"],df_2330['close'])

import numpy as np
df_2330["open-1"] = df_2330['open'].shift(1)
df_2330["close-1"]= df_2330['close'].shift(1)
df_2330['MA_5-1'] = df_2330['close'].shift(1).rolling(5).mean()
df_2330['diff']  = df_2330['close']-df_2330['close'].shift(1) 
df_2330["UD"]    = np.where(df_2330['diff']>0,"U","D")
df_2330

"""## Model / Machine Learning：scikit-learn"""

from sklearn import metrics

"""### 非監督式學習

#### 分群：[K-means](https://medium.com/@a4793706/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-k-means-clustering-in-python-%E9%99%84%E7%A8%8B%E5%BC%8F%E7%A2%BC%E4%BB%8B%E7%B4%B9-55c19bcf2280)
"""

### Explore ==========
import matplotlib.pyplot as plt
df2 = df.copy()
df2["temp"] = 1
colmap = {"2330":'r',"2317":'g',"2603":'b'}
df2['color'] = df['stock_id'].map(lambda x:colmap[x])
plt.scatter(df2["temp"],df2['close'],color=df2['color'])

### Model ==========
from sklearn import cluster

# 建立模型
kmeans_fit = cluster.KMeans(n_clusters = 3).fit(df[["close"]])

# 預測
df2["label"]  = kmeans_fit.labels_
df2

"""衡量績效：組間差異大，組內差異小 => [silhouette_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score)

"""

# 績效
silhouette_avg = metrics.silhouette_score(df[["close"]], df2["label"])
print(silhouette_avg)

### Communicate ==========
colmap = {0:'r',1:'g',2:'b'}
df2['color'] = df2['label'].map(lambda x:colmap[x])
plt.scatter(df2["temp"],df2['close'],color=df2['color'])

"""### 監督式學習：
- X 是要拿來預測的資料
- Y 是想預測的結果

#### 迴歸
- R Squared 接近 1
- MAE, MSE 接近 0
"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split 
df_2330['MA_5'] = df_2330['close'].rolling(5).mean()
training_column = ["MA_5"]
start_index = 4 # 因 MA_5 前4天是空值，`start_index=4`(第五天 index=4 開始計算)

# 切分訓練與測試資料
train_X, test_X, train_Y, test_Y = train_test_split(df_2330[training_column][start_index:], df_2330['close'][start_index:], test_size = 0.3)

# 建立模型
clf = LinearRegression()
data_clf = clf.fit(train_X, train_Y)

# 預測
test_Y_predicted = data_clf.predict(test_X)

# 績效
print('MAE:', metrics.mean_absolute_error(test_Y, test_Y_predicted))  
print('MSE:', metrics.mean_squared_error(test_Y, test_Y_predicted))  
print('R Squared:',data_clf.score(test_X, test_Y))

training_column = ["close-1"]
start_index = 1

# 切分訓練與測試資料
train_X, test_X, train_Y, test_Y = train_test_split(df_2330[training_column][start_index:], df_2330['close'][start_index:], test_size = 0.3)

# 建立模型
clf = LinearRegression()
data_clf = clf.fit(train_X, train_Y)

# 預測
test_Y_predicted = data_clf.predict(test_X)

# 績效
print('MAE:', metrics.mean_absolute_error(test_Y, test_Y_predicted))  
print('MSE:', metrics.mean_squared_error(test_Y, test_Y_predicted))  
print('R Squared:',data_clf.score(test_X, test_Y))

"""由於此份資料為單一股票的日交易資料，為連續性質，  
切分方式以某一時間為切點，之前為訓練資料，拿往後的資料當測試資料，較為符合情境。
"""

training_column = ["close-1"]
start_index = 1
test_limit = 5

# 切分訓練與測試資料
train_X = df_2330[training_column][start_index:len(df_2330)-test_limit]
test_X  = df_2330[training_column][len(df_2330)-test_limit:]
train_Y = df_2330["close"][start_index:len(df_2330)-test_limit]
test_Y  = df_2330["close"][len(df_2330)-test_limit:]

# 建立模型
clf = LinearRegression()
data_clf = clf.fit(train_X, train_Y)

# 預測
test_Y_predicted = data_clf.predict(test_X)

# 績效
print('MAE:', metrics.mean_absolute_error(test_Y, test_Y_predicted))  
print('MSE:', metrics.mean_squared_error(test_Y, test_Y_predicted))  
print('R Squared:',data_clf.score(test_X, test_Y))

"""#### 決策樹"""

from sklearn import tree

training_column = ["open","volume"]
target_column = ["UD"]
start_index = 5
test_limit = 5

# 切分訓練與測試資料
train_X = df_2330[training_column][start_index:len(df_2330)-test_limit]
test_X  = df_2330[training_column][len(df_2330)-test_limit:]
train_Y = df_2330[target_column][start_index:len(df_2330)-test_limit]
test_Y  = df_2330[target_column][len(df_2330)-test_limit:]

# 建立模型
clf = tree.DecisionTreeClassifier(max_depth = 3)
data_clf = clf.fit(train_X, train_Y)


# 預測
test_Y_predicted = data_clf.predict(test_X)

# 績效
accuracy = metrics.accuracy_score(test_Y, test_Y_predicted)
print(accuracy)

"""## Communicate / Visulization"""

import graphviz
dot_data = tree.export_graphviz(clf, out_file=None, 
                                feature_names=training_column,class_names=clf.classes_)

graph = graphviz.Source(dot_data) 
graph

"""#[jieba 中文分詞](https://github.com/fxsjy/jieba)


"""

import jieba
word = "2021年10月之前我取得碩士學位"
seg_list = jieba.cut(word, cut_all=True)
print("Full Mode: " + "/ ".join(seg_list)) 

seg_list = jieba.cut_for_search(word)
print("Search Mode: " + "/ ".join(seg_list))

import jieba.posseg as pseg
seg_list = pseg.cut(word)
for word, flag in seg_list:
    print('{} {}'.format(word, flag))

